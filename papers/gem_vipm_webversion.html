<html>

<head>
<title>Comparison of VIPM Methods</title>

<style>
<!--
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin-top:6.0pt;
	margin-right:0cm;
	margin-bottom:0cm;
	margin-left:0cm;
	margin-bottom:.0001pt;
	text-indent:8.5pt;}
p.Hanging
	{margin-top:6.0pt;
	margin-right:0cm;
	margin-bottom:0cm;
	margin-left:20pt;
	margin-bottom:.0001pt;
	text-indent:-20pt;}
h1
	{margin-top:12.0pt;
	margin-right:0cm;
	margin-bottom:3.0pt;
	margin-left:0cm;
	page-break-after:avoid;}
h2
	{margin-top:12.0pt;
	margin-right:0cm;
	margin-bottom:3.0pt;
	margin-left:0cm;
	page-break-after:avoid;}
p.MsoTitle, li.MsoTitle, div.MsoTitle
	{margin-top:12.0pt;
	margin-right:0cm;
	margin-bottom:3.0pt;
	margin-left:0cm;
	text-align:center;
	text-indent:8.5pt;
	font-size:24.0pt;}
p.MsoBodyTextIndent, li.MsoBodyTextIndent, div.MsoBodyTextIndent
	{margin-top:6.0pt;
	margin-right:0cm;
	margin-bottom:0cm;
	margin-left:0cm;
	margin-bottom:.0001pt;
	text-indent:8.5pt;}
a:link, span.MsoHyperlink
	{color:blue;
	text-decoration:underline;}
p.Code, li.Code, div.Code
	{margin:0cm;
	margin-bottom:.0001pt;
	font-family:monospace;}
@page Section1
	{size:595.3pt 841.9pt;
	margin:72.0pt 90.0pt 72.0pt 90.0pt;}
div.Section1
	{page:Section1;}
 /* List Definitions */
 ol
	{margin-bottom:0cm;}
ul
	{margin-bottom:0cm;}
-->
</style>

</head>

<body lang=EN-GB link=blue vlink="#606420">

<div class=Section1>

<p class=MsoTitle>Comparison of VIPM Methods</p>

<h1>Introduction</h1>

<p class=MsoNormal>View-Independent Progressive Meshing (VIPM)
has moved from the status of an interesting research project, to promising new
technology, to sensible addition to all the best engines, and now into the
Direct3D graphics API itself. Is it now becoming almost required for any engine
and its inclusion in the Direct3DX library means that one form of VIPM is
relatively easy to add.</p>

<p class=MsoNormal>However, in an effort to push the
performance of VIPM, and in particular to drive the hardware as efficiently as
possible, several new forms have been developed, each with their own tradeoffs
and characteristics. This Gem is intended as a guide to some of the more
promising versions, and should help people decide which of the many variants to
use in particular situations.</p>

<p class=MsoNormal>This Gem does assume a basic familiarity
with VIPM, and there is no space for a thorough introduction here. However,
there are several good guides both in print and online. The two best known are
Jan Svarovsky’s Gem in Game Programming Gems 1 [Svarovsky00] and Charles
Blooms’ website [Bloom01], both of which have excellent step-by-step guides to
implementations of the “vanilla” VIPM method. All the methods discussed here
use the same basic collapse/split algorithm, but implement it in different
ways.</p>

<h1>Considerations</h1>

<p class=MsoNormal>There are a few main points that the
various methods need to be judged on. Different situations demand different
choices, and the different ways each object type in a game is used may mean
that different methods of VIPM are used. Things to consider are:</p>

<ul>

<li>
Global memory cost. How much memory is taken up
just by the mesh representation of the model. This memory is shared between all
on-screen instances.</li>

<li>
Instance memory cost. How much memory is used
for each instance of the object drawn on-screen? This memory is duplicated for
each instance and cannot be shared.</li>

<li>
Streaming or referenced memory cost. This is the
amount of data actually referenced on each frame. There may be a large amount
of existing data for an object that is mainly left on CD or swapped out to
hard-drive by virtual memory. However, on each frame the actual amount of data
referenced may be small, allowing the data to be streamed and/or handled
efficiently by the virtual memory system. This is especially important for
consoles that typically have limited memory.</li>

<li>
CPU cost. How many clock cycles the algorithm
takes, in terms of user code. This includes both single-frame rendering costs
and the cost of changing the level of detail from frame to frame.</li>

<li>
API interface efficiency. How many CPU cycles
are used in driver and API interfaces getting data down to the graphics card.</li>

<li>
Bus bandwidth. How much data must be sent to the
graphics card. On a PC, this means the AGP bus bandwidth.</li>

<li>
Vertex–cache coherency. Modern graphics cards
try to fetch, transform and light each vertex only once, even though the vertex
will be used by multiple triangles. To do this they have a vertex cache that
holds the most recently used vertices, and applications need to try to use
vertices in this cache as often as possible to get maximum performance. An
algorithm that uses more triangles than another may still be faster because it
has a higher vertex cache hit rate.</li>
</ul>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Vertex cache coherency will be quoted in
terms of the number of vertices loaded or processed per triangle drawn, or
“vertices per triangle”. Current triangle reordering algorithms for static
(i.e. non-VIPM) meshes, using modern vertex caches of around 16 entries can get
numbers down to around 0.65. For an example, see [Hoppe99]. This gives suitable
benchmark figures to compare efficiencies when the mesh is converted to a VIPM
one. Also note that when calculating the vertices per triangle using triangle
strips, only drawn triangles should be counted, not degenerate ones. The
degenerate triangles are a necessary evil – they don’t add anything to the
scene at all.</p>

<p class=MsoNormal>Algorithms that are good at streaming allow
the application to draw huge worlds that are mostly stored on disk, and to
degrade image quality gracefully if the streaming of data hits a limit
somewhere along the way, such as available disk bandwidth, or available memory
on the machine.</p>

<p class=MsoNormal>This also helps systems with virtual memory
– if the data is accessed linearly, the virtual memory manager can swap out
data that has yet to be accessed, or has not been accessed for a long time.
Static data can be optimized even further and made into a read-only
memory-mapped file. This also ensures that irritating “loading level” messages
are no more tedious than absolutely necessary. The object data does not all
need to be loaded at the start – the player can start playing the level with
low-resolution data and as the detailed models are needed, they will be loaded.</p>

<p class=MsoNormal>All the methods discussed here are based
around implementations of the same fundamental algorithm. Single operations are
done that collapse a single vertex onto another vertex along one of its
triangle edges. No new “average” vertex is generated, and no collapses between
vertices that do not share an edge are allowed. These are worth looking into,
however the current consensus is that they involve a higher runtime cost for
equivalent error levels on most current hardware. Of course, things change, and
new algorithms are always being invented.</p>

<p class=MsoNormal>A note on the terminology used. The
“resolution” of a mesh is proportional to the number or triangles in it. Thus a
“high-resolution” mesh undergoes edge collapses and becomes a
“lower-resolution” mesh. The opposite of an edge collapse is an edge “split”,
where a single vertex splits into two separate vertices. For a given
edge-collapse, there is a “kept” vertex and a “binned” vertex. The binned
vertex is not used in any lower-resolution meshes, the kept vertex is. For a
given edge collapse, there are two types of triangle. Those that use the edge
being collapsed will not be in any lower-resolution mesh, and are “binned.” For
a typical collapse, there are two binned triangles, though there may be more or
less for complex mesh topologies. Those that are not binned, but use the binned
vertex are “changed” triangles, and changed so that they use the kept vertex
instead of the binned vertex. When performing an edge split, the previously
binned vertex and triangles are “new,” though they are often still called
“binned” because typically there are no split data structures, just collapse
data structures that are done in reverse. Most of the perspective is in the
collapsing direction, so words like “first”, “next”, “before” and “after” are
used assuming collapses from a high-triangle mesh to a low-triangle mesh.
Again, splits are done by undoing collapses.</p>

<p class=MsoNormal>This gem will also be talking in a very PC
and DirectX-centric way about CPUs, AGP buses, graphics cards (“the card”),
system/video/AGP memory, index and vertex buffers. This is generally just a
convenience – most consoles have equivalent units and concepts. Where there is
a significant difference, they will be highlighted. The one term that may be
unfamiliar is the AGP bus – this is the bus between the main system memory (and
the CPU) and the graphics card with its memory. There are various speeds, but
this bus is typically capable of around 500Mbytes/sec, which makes it
considerably smaller than the buses between system memory and the CPU, and
between the graphics chip and its video memory. Some consoles have a similar bottleneck,
others use a unified memory scheme that avoids it. In many cases, this is the
limiting factor in PC graphics.</p>

<h1>Vanilla VIPM</h1>

<p class=MsoNormal>This is the best-known version of VIPM, and
the version used by the Direct3DX8 library. It has a global list of static vertices,
arranged in order from last-binned to first-binned. Each time a collapse is
done, the vertex being binned by the collapse is the one at the end of the
list, and the number of vertices used is decremented by one. This ensures that
the used vertices are always in a single continuous block at the start of the
vertex buffer, which means that linear software T&amp;L pipelines always
process only the vertices in use.</p>

<p class=MsoNormal>The triangles are also ordered from
last-binned to first-binned. Each edge collapse generally removes two
triangles, though they may actually remove anywhere from zero upwards for
meshes with complex topologies.</p>

<p class=MsoNormal>Triangles that are not binned but changed
during a collapse simply have the index to the binned vertex changed to that of
the kept vertex. Since the index list changes as the LoD changes, the triangle
index buffer is stored as per-instance data. The index buffer is made up of
indexed triangle lists (each triangle defined by three separate indices),
rather than indexed triangle strips.</p>

<p class=MsoNormal>Each record of collapse data has the
following format:</p>

<p class=Code>&nbsp;</p>

<p class=Code>struct VanillaCollapseRecord</p>

<p class=Code>{</p>

<p class=Code>     // The offset of the vertex that doesn't
vanish/appear.</p>

<p class=Code>     unsigned short  wKeptVert;</p>

<p class=Code>     // Number of tris removed/added.</p>

<p class=Code>     unsigned char   bNumTris;</p>

<p class=Code>     // How many entries in wIndexOffset[].</p>

<p class=Code>     unsigned char   bNumChanges;</p>

<p class=Code>     // How many entries in wIndexOffset[] in
the previous action.</p>

<p class=Code>     unsigned char   bPrevNumChanges;</p>

<p class=Code>     // Packing to get correct short alignment.</p>

<p class=Code>     unsigned char   bPadding[1];</p>

<p class=Code>&nbsp;</p>

<p class=Code>     // The offsets of the indices to change.</p>

<p class=Code>     // This will be of actual length
bNumChanges,</p>

<p class=Code>     // then immediately after in memory will be
the next record.</p>

<p class=Code>     unsigned short  wIndexOffset[];</p>

<p class=Code>};</p>

<p class=MsoNormal>This structure is not a fixed length – <span style='font-family:monospace'>wIndexOffset[]</span> grows to the number of vertices that need changing. This
complicates the access functions slightly, but ensures that when performing
collapses or splits, all the collapse data is in sequential memory addresses,
which allows cache lines and cache pre-fetching algorithms to work efficiently.
It also allows the application to stream or demand-load the collapse data off a
disk very easily. Because it is static and global, it can also be made into a
read-only memory-mapped file, which under many operating systems are extremely
efficient.</p>

<p class=MsoNormal>Although at first glance <span style='font-family:monospace'>bPrevNumChanges </span>doesn’t seem to be needed for collapses, it is needed when doing
splits and going back up the list – the number of <span style='font-family:monospace'>wIndexOffset[]</span> entries in the previous structure is needed so they can be skipped
over. Although this makes for convoluted-looking C, the assembly code produced
is actually very simple.</p>

<p class=MsoNormal>To perform a collapse, the number of
vertices used is decremented, since the binned vertex is always the one on the
end. The number of triangles is reduced by <span style='font-family:monospace'>bNumTris</span> – again, the binned triangles are always the ones on the end of the
list.</p>

<p class=MsoNormal>The changed triangles all need to be
redirected to use the kept vertex instead of the binned one. The offsets of the
indices that refer to the binned point are held in <span style='font-family:monospace'>wIndexOffset[]</span>. Each one references an index that needs to be changed from the
binned vertex’s index (which will always be the last one) to the kept vertex’s
index – <span style='font-family:monospace'>wKeptVert</span>:</p>

<p class=Code>&nbsp;</p>

<p class=Code>     </p>

<p class=Code>VanillaCollapseRecord *pVCRCur = the current
collapse;</p>

<p class=Code>iCurNumVerts--;</p>

<p class=Code>iCurNumTris -= pVCRCur-&gt;bNumTris;</p>

<p class=Code>&nbsp;</p>

<p class=Code>unsigned short *pwIndices;</p>

<p class=Code>// Get the pointer to the instance index buffer.</p>

<p class=Code>pIndexBuffer-&gt;Lock ( &amp;pwIndices );</p>

<p class=Code>for ( int i = 0; i &lt; pVCRCur-&gt;bNumChanges;
i++ )</p>

<p class=Code>{</p>

<p class=Code>     ASSERT (
pwIndices[pVCRCur-&gt;wIndexOffset[i]] == (unsigned short)iCurNumVerts );</p>

<p class=Code>     pwIndices[pVCRCur-&gt;wIndexOffset[i]] = pVCRCur-&gt;wKeptVert;</p>

<p class=Code>}</p>

<p class=Code>// Give the index buffer back to the hardware.</p>

<p class=Code>pIndexBuffer-&gt;Unlock();</p>

<p class=Code>// Remember, it’s not a simple ++ (though the
operator could be overloaded).</p>

<p class=Code>pVCRCur = pVCRCur-&gt;Next();</p>

<p class=Code>&nbsp;</p>

<p class=MsoNormal>Note that reading from hardware index
buffers can be a bad idea on some architectures, so be careful of exactly what
that <span style='font-family:monospace'>ASSERT()</span> is doing – it is mainly for illustration purposes.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>[<span style='color:red'>Figure 1 - insert
VIPM_fig1.SDR]</span></p>

<p class=MsoNormal>Figure 1 – An edge collapse with before and
after index lists and the VanillaCollapseRecord.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Doing a split is simply a matter of
reversing the process:</p>

<p class=Code>&nbsp;</p>

<p class=Code>VanillaCollapseRecord *pVCRCur = the current
collapse;</p>

<p class=Code>pVCRCur = pVCRCur-&gt;Prev();</p>

<p class=Code>unsigned short *pwIndices;</p>

<p class=Code>pIndexBuffer-&gt;Lock ( &amp;pwIndices );</p>

<p class=Code>for ( int i = 0; i &lt; pVCRCur-&gt;bNumChanges;
i++ )</p>

<p class=Code>{</p>

<p class=Code>     ASSERT (
pwIndices[pVCRCur-&gt;wIndexOffset[i]] == pVCRCur-&gt;wKeptVert );</p>

<p class=Code>     pwIndices[pVCRCur-&gt;wIndexOffset[i]] =
(unsigned short)iCurNumVerts;</p>

<p class=Code>}</p>

<p class=Code>iCurNumTris += pVCRCur-&gt;bNumTris;</p>

<p class=Code>iCurNumVerts++;</p>

<p class=Code>&nbsp;</p>

<p class=Code>pIndexBuffer-&gt;Unlock();</p>

<p class=Code>&nbsp;</p>

<p class=MsoNormal>Note – in practice, and for arbitrary
historical reasons, in the sample code the <span style='font-family:monospace'>VertexCollapseRecords</span> are stored last first, so the <span style='font-family:monospace'>Prev()</span> and <span style='font-family:monospace'>Next()</span> calls are swapped.</p>

<p class=MsoNormal>Vanilla VIPM is simple, easy to code, and
has decent speed. It should probably be the first version used for any
evaluation of VIPM, because it is so simple, and even this will give good
scalability, streaming, and so on.</p>

<p class=MsoNormal>The good thing about vanilla VIPM is that
it streams very well. Collapse information and index buffer data is completely
linear in memory and ordered by collapse, so implementing a streaming system
with fallbacks for when data is not available immediately is extremely easy.</p>

<p class=MsoNormal>However, there are many bad things about
vanilla VIPM. Vertex cache coherency is poor. Because triangle order is
strictly determined by collapse order, there is no way to reorder triangles for
better vertex caching.</p>

<p class=MsoNormal>Another problem is the relatively large
per-instance memory use. The whole index data chunk needs to be replicated for
each instance. This can be reduced by only allocating as many indices as is
actually currently being used, and growing or shrinking as needed (along with a
bit of hysteresis to prevent calling <span style='font-family:monospace'>malloc()</span> and <span style='font-family:monospace'>free()</span> all the time), but it is still large if there are lots of objects
on-screen.</p>

<p class=MsoNormal>And finally, vanilla VIPM only works with
indexed triangle lists, which can be a poor choice for hardware that prefers
strips.</p>

<h1>Skipstrips</h1>

<p class=MsoNormal>Skipstrips is a slightly overloaded name.
It was borrowed from a paper on View-Dependent Progressive Meshing (VDPM)
[El-Sana99]. VDPM is significantly more complex and requires some fairly
extensive data structures to achieve good efficiency, and a skiplist is one of
those data structures. However, the section that inspired this VIPM method was
the bit that noted that to bin a triangle, it does not have to fall off the end
of the index list, as in vanilla. There is not much wrong with simply making it
degenerate by moving one of its vertices (usually the binned vertex) to another
one (usually the kept vertex), and leaving it in the list of drawn triangles.
Hardware is very good at spotting degenerate triangles, and throws them away
very quickly without trying to draw any pixels.</p>

<p class=MsoNormal>This means that the order of triangles is
no longer determined by collapse order – they can be ordered by some other
criteria. The cunning thing that the original SkipStrips paper pointed out is
that triangles can now be ordered into strip order, and indeed converted into
strips. This is great for hardware that prefers their data in strip order.
Since this VIPM method was inspired by the paper, it inherited the name,
despite it being somewhat inaccurate.</p>

<p class=MsoNormal>The ability to reorder triangles increases
vertex cache coherency. Strips are naturally good at this – they have an
implicit 1.0 vertices per triangle efficiency (for long strips with no
degenerates), and with the right ordering and a decent-sized vertex cache they
can get much lower values.</p>

<p class=MsoNormal>One cunning thing about the implementation
is that the collapse/split routines and data structures are virtually identical
to vanilla VIPM. The only change is that the number of drawn triangles does not
change with collapses and splits. Triangles simply become degenerate, they do
not fall off the end of the list.</p>

<p class=MsoNormal>However, this shows up a big problem with
skipstrips. After lots of collapses, there are lots and lots of degenerate
triangles in the list. Although they are rejected by the hardware quickly, they
still take some time to reject, and their index data still has to be sent to
the card. This eats into the bus bandwidth, and lowers the visible triangle
throughput in triangles/second.</p>

<p class=MsoNormal>After a lot of collapses, the vertex cache
efficiency has also dropped. The nice neat strips will have been bent and
broken by the collapses, and this disrupts the cache efficiency. Also, as
triangles become degenerate, the number of indices referring to one of the
remaining vertices increases. A collapse that bins that vertex must change all
the indices that refer to it, including the degenerate triangles. So the more
collapses that get done, the more expensive each collapse becomes, because the
size of <span style='font-family:monospace'>wIndexOffset[]</span> grows. This does not scale with the number of triangles drawn,
which is no good, since that is the whole point of VIPM – things at lower
detail should take less time to render.</p>

<h1>Multi-level Skipstrips</h1>

<p class=MsoNormal>Fortunately, there is a solution to most of
skipstrip’s woes. After a certain number of collapses, simply stop, take the
current geometry with all of its collapses done, throw away the degenerate
triangles, and start making a completely new skipstrip from scratch. Continue
collapses with this new skipstrip until it too becomes inefficient, and so on.</p>

<p class=MsoNormal>When creating each new skipstrip level, all
the degenerate triangles are thrown away, which reduces the number of triangles
(both visible and degenerate) that are sent to the card. The triangles are also
reordered to make lists that are again vertex-cache-optimal. New collapses
don’t need to change lots of degenerate triangle indices each time, each
instance only needs to copy the skipstrip level that it actually uses, and they
get shorter with decreasing detail.</p>

<p class=MsoNormal>The different index lists can be stored
globally, since when switching to a new list a new copy is taken and then
refined with collapses to exactly the number of triangles wanted. So the fact
that there are now multiple index lists is not too bad – it’s global data. This
also restores some of the nice streaming-friendliness that the vanilla method
has. The granularity is a bit coarser – the whole of an index list must be
grabbed before anything can be rendered using that level, but at least it’s no
longer an all-or-nothing thing, and the lower-resolution index lists are
actually very small.</p>

<p class=MsoNormal>For a bit more efficiency, two versions of
the index lists can be stored in global space – fully collapsed (before switching
to a lower-resolution list that is) and fully uncollapsed. This means that a
single-collapse oscillation across the boundary between two index lists is
still fairly efficient. If only the uncollapsed versions are held, each time
the LoD increases, the higher-resolution index list must be copied, and then
all its collapses need to be performed to draw the next frame. Having the
collapsed versions stored as well means that a change in LoD of n collapses
only actually requires n collapses to be done (and sometimes fewer).</p>

<p class=MsoNormal>The actual collapse/split code and
structures are the same as for standard skipstrips, except that there is a
global array of structures holding the pre-made index lists, the collapse lists
for each one, and the number of collapses in each. Before doing any collapses
or splits, the code checks to see if it needs to change level, and if so copies
the new level’s index list and starts doing collapses/splits until it reaches
the right LoD within that level.</p>

<p class=MsoNormal>So this has fixed all the bad things about
skipstrips when compared to vanilla in exchange for an increase in global (but
easily streamed or swapped) memory.</p>

<p class=MsoNormal>Skipstrips also have an equivalent using
triangle lists instead of triangle strips. The principle is exactly the same,
but using a different primitive. Some algorithms require lists rather than
strips, and some vertex cache routines can obtain slightly higher caching rates
with lists than strips. But no separate implementation was done in the sample
code, because they are so similar.</p>

<h1>Mixed Mode VIPM</h1>

<p class=MsoNormal>One of the problems with the types of VIPM
mentioned so far is that the whole index list needs to be copied for each
instance of the object. This can be quite a burden in some cases, especially on
machines with limited memory, notably consoles, where everything has to be
shoehorned into memory that is usually half the size that the programmers would
like, even before VIPM is mentioned. It would be excellent if some of this
index list could be moved to global (i.e. static and shared between instances)
memory instead of having to be copied for each instance.</p>

<p class=MsoNormal>On a multi-level skipstrip, a lot of the
triangles are not affected even when that level is fully collapsed. So there is
no need to copy those triangles per-instance; they can be global and shared
between instances. In fact, for this algorithm indexed lists are used – the
indexed strip case will be discussed afterwards as a variant. At each level,
the triangles are split into four lists:</p>

<p class=MsoNormal style='margin-left:26.5pt;text-indent:-18.0pt'>1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
The triangles that are not affected by any
collapses.</p>

<p class=MsoNormal style='margin-left:26.5pt;text-indent:-18.0pt'>2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
The triangles that are binned by collapses, but
not modified by any before they are binned.</p>

<p class=MsoNormal style='margin-left:26.5pt;text-indent:-18.0pt'>3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
The triangles that are modified by collapses,
but not binned.</p>

<p class=MsoNormal style='margin-left:26.5pt;text-indent:-18.0pt'>4.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
The triangles that are first modified by one or
more collapses and then binned.</p>

<p class=MsoNormal>Lists 2 and 4 are each sorted by bin order,
just as for vanilla VIPM. Lists 1 and 3 are sorted into whatever order gives
the highest vertex cache efficiency. Then list 2 is appended to list 1, and the
combined list is put into a global index buffer, static and shared by all instances.
List 4 is appended to list 3, and the combined dynamic list is copied into
instances when they use that level. This list is then modified at runtime using
exactly the same modification algorithm as vanilla VIPM.</p>

<p class=MsoNormal>To draw the mesh, the required collapses
and splits are done to the dynamic per-instance list, and the list is drawn.
Then the associated level’s static list is drawn, with the only modification
being that the number of triangles drawn will change as static triangles are
collapsed.</p>

<p class=MsoNormal>The code and structures needed are based on
the multi-level skiplist, except that for each level there are two lists – the
copied dynamic one and the shared static one. The other change is that there
are two triangle counts, one for each list, and a collapse may alter either or
both of these numbers. So the <span style='font-family:monospace'>bNumTris</span> member is replaced
by <span style='font-family:monospace'>bNumStaticTris</span> and <span style='font-family:monospace'>bNumDynamicTris</span>, and the appropriate
increment and decrements added.</p>

<p class=MsoNormal>This means that a large proportion of each
mesh is being drawn from a static index buffer that is tuned for vertex cache
coherency (list 1). It is not quite as good as it could be, since the triangles
in this list only make up part of the object. There will be “holes” in the mesh
where triangles have been moved to the other three lists, and this decreases
both the maximum and the actual vertex per triangle numbers that are obtained.
Some of the dynamic buffer is also ordered for optimal vertex cache behavior
(list 3), though collapses can interfere with this efficiency, and the mesh for
list 3 is usually far from usefully connected, so there is a limit to what any
reordering can do.</p>

<p class=MsoNormal>Like all multi-level methods, it is
streaming/friendly, though in this case, since the lists are ordered by
collapse order, the granularity is even finer – at the triangle level, not just
the list level. Whether this is a terribly exciting thing is a different
question – the finer control is probably not going to make much of a difference
to performance.</p>

<p class=MsoNormal>This does require two DrawIndexedPrimitive
calls to Direct3D (or equivalent API), though on most platforms this is not a
bottleneck and does not affect rendering speed. It may be important for very
low-triangle meshes, and for these, switching to another method may be
appropriate.</p>

<h1>Mixed Mode Skipstrips</h1>

<p class=MsoNormal>Identical to mixed mode lists, except that
strips are used, and instead of the dynamic list being done with vanilla VIPM,
it is done using the skipstrips algorithm. As with skipstrips, using strips
means that ordering by collapse order is too inefficient, and this means that list
2 triangles now have to be binned by being made degenerate. This forces them to
become dynamic instead of static, and they join lists 3 and 4. The triangles
from these three lists are merged together and treated as a skipstrip –
reordered for optimal vertex cache efficiency, copied for each instance, and
modified by collapse information.</p>

<p class=MsoNormal>The disadvantages with this method are that
there is now more data being copied for each instance, and because the
triangles are ordered by strip order not collapse order, triangles cannot be
binned entirely by simply dropping them off the end of the index list. However,
both these factors are only mildly worse than the list version, and if the
hardware needs to be fed strips, this is still an excellent method.</p>

<h1>Sliding Window</h1>

<p class=MsoNormal>Sliding window VIPM introduces the idea of
fully static and global index buffers, with no editing of indices, and
therefore a tiny amount of per-instance memory.</p>

<p class=MsoNormal>Sliding window notes that when a collapse
happens, there are two classes of triangles – binned triangles and modified
triangles. However, there is no real need for the modified triangles to
actually be at the same physical position in the index buffer before and after
the collapse. The old version of the triangles could simply drop off the end of
the index buffer along with the binned triangles, and the new versions added on
at the other end.</p>

<p class=MsoNormal>So instead of an example collapse binning
two triangles and editing three others, it actually bins five triangles and
adds three new ones. Both operations are performed by just changing the first
and last indices used for rendering – sliding a “rendering window” along the
index buffer.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>[<span style='color:red'>Figure 2 – insert
VIPM_fig2.sdr]</span></p>

<p class=MsoNormal>Figure 2 – a collapse showing the index
list and the two windows.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>The index buffer is split into three
sections. At the start are triangles added as a result of changes, in reverse
collapse order. In the middle are triangles not affected by collapses, in any
(vertex cache-optimal) order. And at the end are triangles binned or changed by
collapses, again ordered in reverse collapse order - first collapse at the end.
Note that a triangle modified as the result of a collapse cannot then be
involved (either binned or changed) in another collapse. To be modified by a
second collapse would mean that triangle would have to fall off the end of the
index buffer. But it has already been added to the start – it cannot then also
fall off the end – the chance of the ordering being just right to allow this
are incredibly slim.</p>

<p class=MsoNormal>So once a triangle has been modified by a
collapse, the only way it can be involved in another collapse is if a new index
buffer is started that has all the same triangles as the previous (collapsed)
one. The ordering of this new one is not constrained by the previous collapses,
and so can be sorted by new collapses. So again the multi-level concept is
used, but in this case because further collapses cannot happen without it, not
simply for efficiency.</p>

<p class=MsoNormal>The problem with this at face value is that
algorithms such as QEM give an ordering for collapses. If this ordering is
followed strictly